from option import args
import model
import utils
import data.common as common

import torch
import numpy as np
import os
import glob
import cv2
import time
import psutil
from thop import profile
from torch.utils.tensorboard import SummaryWriter

device = torch.device('cpu' if args.cpu else 'cuda')


def test_model_performance(args, sr_model, sample_input=None):
    """æµ‹è¯•æ¨¡åž‹æ€§èƒ½ï¼šå‚æ•°é‡ã€FLOPsã€å†…å­˜å ç”¨ã€å¤„ç†æ—¶é—´"""

    print("\n" + "="*60)
    print("æ¨¡åž‹æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
    print("="*60)

    # 1. æµ‹è¯•å‚æ•°é‡
    total_params = sum(p.numel() for p in sr_model.parameters())
    trainable_params = sum(p.numel() for p in sr_model.parameters() if p.requires_grad)

    print(f"ðŸ“Š æ¨¡åž‹å‚æ•°é‡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")
    print(f"  æ¨¡åž‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")  # å‡è®¾float32

    # 2. æµ‹è¯•FLOPs
    print(f"\nðŸ”¢ FLOPsè®¡ç®—:")
    if sample_input is None:
        # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹è¾“å…¥
        if not args.cubic_input:
            sample_input = torch.randn(1, 3, 64, 64).to(device)
        else:
            sample_input = torch.randn(1, 3, 256, 256).to(device)

    try:
        flops, params = profile(sr_model, inputs=(sample_input,), verbose=False)
        print(f"  FLOPs: {flops:,}")
        print(f"  FLOPs (G): {flops / 1e9:.2f} G")
        print(f"  å‚æ•°é‡ (M): {params / 1e6:.2f} M")
    except Exception as e:
        print(f"  FLOPsè®¡ç®—å¤±è´¥: {e}")

    # 3. æµ‹è¯•å†…å­˜å ç”¨
    print(f"\nðŸ’¾ å†…å­˜å ç”¨:")

    # GPUå†…å­˜å ç”¨
    if torch.cuda.is_available() and not args.cpu:
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

        # è®°å½•åˆå§‹GPUå†…å­˜
        if args.test_block:
            initial_memory = torch.cuda.memory_allocated()

            # æ‰§è¡Œå‰å‘ä¼ æ’­
            with torch.no_grad():
                _ = sr_model(sample_input)

            torch.cuda.synchronize()
            peak_memory = torch.cuda.max_memory_allocated()
            memory_used = peak_memory - initial_memory

            print(f"  GPUå†…å­˜å ç”¨: {memory_used / 1024 / 1024:.2f} MB")
        else:
            initial_memory = torch.cuda.memory_allocated()
            with torch.no_grad():
                _ = sr_model(sample_input)
            torch.cuda.synchronize()
            peak_memory = torch.cuda.max_memory_allocated()
            memory_used = peak_memory - initial_memory
            print(f"  GPUå†…å­˜å ç”¨: {memory_used / 1024 / 1024:.2f} MB")
    else:
        print(f"  CPUæ¨¡å¼ - GPUå†…å­˜: 0 MB")

    # CPUå†…å­˜å ç”¨
    process = psutil.Process()
    cpu_memory = process.memory_info().rss / 1024 / 1024
    print(f"  CPUå†…å­˜å ç”¨: {cpu_memory:.2f} MB")

    # 4. æµ‹è¯•å¤„ç†æ—¶é—´
    print(f"\nâ±ï¸  å¤„ç†æ—¶é—´æµ‹è¯•:")

    # é¢„çƒ­
    with torch.no_grad():
        for _ in range(5):
            _ = sr_model(sample_input)

    if torch.cuda.is_available() and not args.cpu:
        torch.cuda.synchronize()

    # æ­£å¼æµ‹è¯•
    times = []
    for i in range(10):  # æµ‹è¯•10æ¬¡å–å¹³å‡
        if torch.cuda.is_available() and not args.cpu:
            torch.cuda.synchronize()
            start_time = time.time()

            with torch.no_grad():
                _ = sr_model(sample_input)

            torch.cuda.synchronize()
            end_time = time.time()
        else:
            start_time = time.time()
            with torch.no_grad():
                _ = sr_model(sample_input)
            end_time = time.time()

        elapsed = end_time - start_time
        times.append(elapsed)

        if i == 0:  # ç¬¬ä¸€æ¬¡å¯èƒ½æ¯”è¾ƒæ…¢ï¼Œè·³è¿‡
            continue

    avg_time = np.mean(times)
    std_time = np.std(times)
    min_time = np.min(times)
    max_time = np.max(times)

    print(f"  å¹³å‡å¤„ç†æ—¶é—´: {avg_time * 1000:.2f} ms")
    print(f"  æ ‡å‡†å·®: {std_time * 1000:.2f} ms")
    print(f"  æœ€å¿«æ—¶é—´: {min_time * 1000:.2f} ms")
    print(f"  æœ€æ…¢æ—¶é—´: {max_time * 1000:.2f} ms")

    # 5. åžåé‡è®¡ç®—
    input_size = sample_input.shape
    if not args.cubic_input:
        output_size = (input_size[2] * args.scale[0], input_size[3] * args.scale[0])
    else:
        output_size = input_size[2:]

    pixels_processed = output_size[0] * output_size[1]
    throughput = pixels_processed / (avg_time * 1000)  # åƒç´ /æ¯«ç§’

    print(f"\nðŸ“ˆ åžåé‡:")
    print(f"  è¾“å…¥å°ºå¯¸: {input_size[2]}x{input_size[3]}")
    print(f"  è¾“å‡ºå°ºå¯¸: {output_size[0]}x{output_size[1]}")
    print(f"  åžåé‡: {throughput:.0f} åƒç´ /æ¯«ç§’")
    print(f"  FPS (ä¼°ç®—): {1000/avg_time:.1f}")

    print("="*60 + "\n")

    return {
        'total_params': total_params,
        'trainable_params': trainable_params,
        'flops': flops if 'flops' in locals() else 0,
        'memory_used': memory_used if 'memory_used' in locals() else 0,
        'avg_time': avg_time,
        'fps': 1000/avg_time if avg_time > 0 else 0
    }


def deploy(args, sr_model):

    img_ext = '.tif'
    img_lists = glob.glob(os.path.join(args.dir_data, '*'+img_ext))

    if len(img_lists) == 0:
        print("Error: there are no images in given folder!")

    if not os.path.exists(args.dir_out):
        os.makedirs(args.dir_out)

    with torch.no_grad():
        for i in range(len(img_lists)):
            print("[%d/%d] %s" % (i+1, len(img_lists), img_lists[i]))
            lr_np = cv2.imread(img_lists[i], cv2.IMREAD_COLOR)
            lr_np = cv2.cvtColor(lr_np, cv2.COLOR_BGR2RGB)

            if args.cubic_input:
                lr_np = cv2.resize(lr_np, (lr_np.shape[0] * args.scale[0], lr_np.shape[1] * args.scale[0]),
                                interpolation=cv2.INTER_CUBIC)

            lr = common.np2Tensor([lr_np], args.rgb_range)[0].unsqueeze(0)

            if args.test_block:
                # test block-by-block

                b, c, h, w = lr.shape
                factor = args.scale[0]
                tp = args.patch_size
                if not args.cubic_input:
                    ip = tp // factor
                else:
                    ip = tp

                assert h >= ip and w >= ip, 'LR input must be larger than the training inputs'
                if not args.cubic_input:
                    sr = torch.zeros((b, c, h * factor, w * factor))
                else:
                    sr = torch.zeros((b, c, h, w))

                for iy in range(0, h, ip):

                    if iy + ip > h:
                        iy = h - ip
                    ty = factor * iy

                    for ix in range(0, w, ip):

                        if ix + ip > w:
                            ix = w - ip
                        tx = factor * ix

                        # forward-pass
                        lr_p = lr[:, :, iy:iy + ip, ix:ix + ip]
                        lr_p = lr_p.to(device)
                        sr_p = sr_model(lr_p)
                        sr[:, :, ty:ty + tp, tx:tx + tp] = sr_p

            else:

                lr = lr.to(device)
                sr = sr_model(lr)

            sr_np = np.array(sr.cpu().detach())
            sr_np = sr_np[0, :].transpose([1, 2, 0])
            lr_np = lr_np * args.rgb_range / 255.

            # Again back projection for the final fused result
            for bp_iter in range(args.back_projection_iters):
                sr_np = utils.back_projection(sr_np, lr_np, down_kernel='cubic',
                                           up_kernel='cubic', sf=args.scale[0], range=args.rgb_range)
            if args.rgb_range == 1:
                final_sr = np.clip(sr_np * 255, 0, args.rgb_range * 255)
            else:
                final_sr = np.clip(sr_np, 0, args.rgb_range)

            final_sr = final_sr.astype(np.uint8)
            final_sr = cv2.cvtColor(final_sr, cv2.COLOR_RGB2BGR)
            cv2.imwrite(os.path.join(args.dir_out, os.path.split(img_lists[i])[-1]), final_sr)



if __name__ == '__main__':

    # args parameter setting
    # You can configure these paths via command line arguments or set them here
    args.pre_train = '/root/autodl-tmp/TransENet/experiment/TRANSENETx4_UCMerced/model/model_best.pt'
    # args.dir_data = '/root/autodl-tmp/TransENet/datasets/AID-train/AID-dataset/test/LR_x4'
    args.dir_data = '/root/autodl-tmp/TransENet/datasets/UCMerced-train/UCMerced-dataset/test/LR_x4'
    args.dir_out = '../experiment/results/UCMerced_UCMercedtest/x4'

    print("Configuration:")
    print(f"  Model: {args.model}")
    print(f"  Scale: {args.scale}")
    print(f"  Data dir: {args.dir_data}")
    print(f"  Output dir: {args.dir_out}")
    print(f"  Pre-trained model: {args.pre_train}")
    print("-" * 50)

    checkpoint = utils.checkpoint(args)
    sr_model = model.Model(args, checkpoint)
    sr_model.eval()

    # æ¨¡åž‹æ€§èƒ½æµ‹è¯•
    test_model_performance(args, sr_model)

    # # analyse the params of the load model
    # pytorch_total_params = sum(p.numel() for p in sr_model.parameters())
    # print(pytorch_total_params)
    # pytorch_total_params2 = sum(p.numel() for p in sr_model.parameters() if p.requires_grad)
    # print(pytorch_total_params2)
    #
    # for name, p in sr_model.named_parameters():
    #     print(name)
    #     print(p.numel())
    #     print('========')

    deploy(args, sr_model)