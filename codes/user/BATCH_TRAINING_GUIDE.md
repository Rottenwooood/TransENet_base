# ğŸš€ æ‰¹é‡è®­ç»ƒç®¡ç†ç³»ç»Ÿ - å®Œæ•´ä½¿ç”¨æŒ‡å—

è¿™ä¸ªæ‰¹é‡è®­ç»ƒç®¡ç†ç³»ç»Ÿå¸®åŠ©ä½ é«˜æ•ˆåœ°ç®¡ç†è¶…å‚æ•°å®éªŒï¼Œè¿›è¡Œä¸²è¡Œè®­ç»ƒï¼Œå¹¶åˆ†æç»“æœã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
codes/
â”œâ”€â”€ batch_train.py              # é€šç”¨æ‰¹é‡è®­ç»ƒè„šæœ¬
â”œâ”€â”€ quick_batch.py             # å¿«é€Ÿæ‰¹é‡è®­ç»ƒè„šæœ¬
â”œâ”€â”€ analyze_experiments.py      # å®éªŒç»“æœåˆ†æå·¥å…·
â”œâ”€â”€ experiments_config.json     # å®éªŒé…ç½®æ–‡ä»¶æ¨¡æ¿
â”œâ”€â”€ wandb_utils.py             # WandBç›‘æ§å·¥å…·
â”œâ”€â”€ train_enhanced.py          # å¢å¼ºè®­ç»ƒè„šæœ¬
â””â”€â”€ experiment/                # å®éªŒç»“æœç›®å½•
    â”œâ”€â”€ experiment_results.csv # å®éªŒç»“æœæ•°æ®
    â””â”€â”€ analysis_output/        # åˆ†æå›¾è¡¨è¾“å‡º
```

## ğŸ¯ ä¸‰ç§ä½¿ç”¨æ–¹å¼

### æ–¹å¼ä¸€ï¼šå¿«é€Ÿæ‰¹é‡è®­ç»ƒï¼ˆæ¨èæ–°æ‰‹ï¼‰

**ç‰¹ç‚¹**: é¢„è®¾å‡ ç§å¸¸ç”¨å®éªŒé…ç½®ï¼Œä¸€é”®å¼€å§‹

```bash
# 1. åˆ—å‡ºæ‰€æœ‰é¢„è®¾é…ç½®
python quick_batch.py --list

# 2. è¿è¡Œå­¦ä¹ ç‡å¯¹æ¯”å®éªŒ
python quick_batch.py --preset lr_comparison

# 3. è¿è¡Œæ‰€æœ‰é¢„è®¾å®éªŒï¼ˆè°¨æ…ä½¿ç”¨ï¼ï¼‰
python quick_batch.py --all

# 4. è¯•è¿è¡Œï¼ˆä¸å®é™…æ‰§è¡Œï¼‰
python quick_batch.py --preset optimizer_comparison --dry-run
```

**é¢„è®¾é…ç½®**:
- `lr_comparison` - å­¦ä¹ ç‡å¯¹æ¯”å®éªŒ (1e-4, 2e-4, 5e-4)
- `optimizer_comparison` - ä¼˜åŒ–å™¨å¯¹æ¯”å®éªŒ (ADAMW vs ADAM)
- `width_comparison` - æ¨¡å‹å®½åº¦å¯¹æ¯”å®éªŒ (32, 48, 64)
- `loss_comparison` - æŸå¤±å‡½æ•°å¯¹æ¯”å®éªŒ (L1, L1+FFT)

### æ–¹å¼äºŒï¼šè‡ªå®šä¹‰æ‰¹é‡è®­ç»ƒï¼ˆæ¨èé«˜çº§ç”¨æˆ·ï¼‰

**ç‰¹ç‚¹**: å®Œå…¨è‡ªå®šä¹‰è¶…å‚æ•°ç½‘æ ¼ï¼Œé€‚åˆæ·±åº¦è°ƒä¼˜

```bash
# 1. åˆ›å»ºè‡ªå®šä¹‰é…ç½®æ–‡ä»¶
python batch_train.py --create-config

# 2. ç¼–è¾‘ experiments_config.json æ–‡ä»¶
vim experiments_config.json

# 3. æŸ¥çœ‹å°†è¿è¡Œçš„å®éªŒ
python batch_train.py --config experiments_config.json --list

# 4. è¯•è¿è¡Œ
python batch_train.py --config experiments_config.json --dry-run

# 5. æ‰§è¡Œæ‰¹é‡è®­ç»ƒ
python batch_train.py --config experiments_config.json
```

### æ–¹å¼ä¸‰ï¼šæ··åˆä½¿ç”¨ï¼ˆæ¨èä¸“ä¸šç”¨æˆ·ï¼‰

**ç‰¹ç‚¹**: ç»“åˆä¸¤ç§æ–¹å¼çš„ä¼˜ç‚¹

```bash
# 1. å…ˆç”¨å¿«é€Ÿæ¨¡å¼æ¢ç´¢å‡ ä¸ªå…³é”®å‚æ•°
python quick_batch.py --preset lr_comparison --no-wandb

# 2. åˆ†æç»“æœï¼Œæ‰¾å‡ºæœ€ä½³å­¦ä¹ ç‡
python analyze_experiments.py --top 3

# 3. åŸºäºç»“æœï¼Œåˆ›å»ºè‡ªå®šä¹‰å®éªŒ
python batch_train.py --create-config

# 4. ç²¾ç»†è°ƒä¼˜å…¶ä»–å‚æ•°
python batch_train.py --config my_experiments.json
```

## ğŸ“Š å®éªŒé…ç½®è¯¦è§£

### experiments_config.json é…ç½®è¯´æ˜

```json
{
  "base_config": {
    "model": "SYMUNET_PRETRAIN",     // æ¨¡å‹æ¶æ„
    "dataset": "UCMerced",           // æ•°æ®é›†
    "scale": 4,                      // è¶…åˆ†è¾¨ç‡å€æ•°
    "epochs": 300,                   // è®­ç»ƒè½®æ•°
    "batch_size": 4,                 // æ‰¹æ¬¡å¤§å°
    "ext": "img",                   // æ•°æ®æ ¼å¼
    "patch_size": 192               // å›¾åƒå—å¤§å°
  },
  "hyperparameter_grid": {
    "optimizer": ["ADAMW", "ADAM"],        // è¦å¯¹æ¯”çš„ä¼˜åŒ–å™¨
    "scheduler": ["cosine", "step"],      // å­¦ä¹ ç‡è°ƒåº¦å™¨
    "lr": [1e-4, 2e-4, 5e-4],           // å­¦ä¹ ç‡
    "loss": [                              // æŸå¤±å‡½æ•°
      "1*L1",
      "1*L1+0.005*FFT"
    ],
    "symunet_pretrain_width": [32, 48, 64],  // æ¨¡å‹å®½åº¦
    "symunet_pretrain_enc_blk_nums": [        // ç¼–ç å™¨æ·±åº¦
      "2,2,2",
      "4,4,4"
    ]
  },
  "experiment_prefix": "my_exp",           // å®éªŒå‰ç¼€
  "max_experiments": 20,                   // æœ€å¤§å®éªŒæ•°é‡
  "use_wandb": true,                       // æ˜¯å¦ä½¿ç”¨WandB
  "wandb_project": "MyProject",            // WandBé¡¹ç›®å
  "save_every_n_steps": 50,                // æ¯Næ­¥ä¿å­˜æ£€æŸ¥ç‚¹
  "run_name_pattern": "{prefix}_lr{lr}_opt{optimizer}"  // å®éªŒå‘½åæ¨¡å¼
}
```

## ğŸ”§ è¶…å‚æ•°ç½‘æ ¼å»ºè®®

### å¯¹äºé¥æ„Ÿå›¾åƒSRçš„æ¨èé…ç½®

```json
{
  "hyperparameter_grid": {
    "optimizer": ["ADAMW"],                    // é¥æ„Ÿå›¾åƒæ¨èADAMW
    "scheduler": ["cosine"],                  // ä½™å¼¦é€€ç«æ›´ç¨³å®š
    "lr": [1e-4, 2e-4],                     // å­¦ä¹ ç‡èŒƒå›´
    "loss": [
      "1*L1+0.005*FFT",                     // ç©ºé—´+é¢‘ç‡æŸå¤±
      "1*L1+0.01*FFT"
    ],
    "symunet_pretrain_width": [32, 48, 64], // å†…å­˜é™åˆ¶ä¸‹çš„å®½åº¦
    "symunet_pretrain_enc_blk_nums": [
      "2,2,2",                               // åŸºç¡€é…ç½®
      "4,6,6"                                // æ·±åº¦é…ç½®
    ],
    "symunet_pretrain_dec_blk_nums": [
      "2,2,2",
      "6,6,4"
    ]
  }
}
```

### å®éªŒæ•°é‡æ§åˆ¶

| è¶…å‚æ•°æ•°é‡ | æ€»ç»„åˆæ•° | æ¨èå®éªŒæ•° | è¯´æ˜ |
|-----------|----------|------------|------|
| 2-3ä¸ª     | 8-27     | 8-20       | å¿«é€Ÿæ¢ç´¢ |
| 4-5ä¸ª     | 32-243   | 20-50      | æ·±åº¦è°ƒä¼˜ |
| 6+ä¸ª      | 64+      | 50+        | å…¨é¢æœç´¢ |

## ğŸ“ˆ ç»“æœåˆ†æ

### åŸºæœ¬åˆ†æ

```bash
# æ˜¾ç¤ºå®éªŒæ‘˜è¦
python analyze_experiments.py

# æ˜¾ç¤ºæœ€ä½³å®éªŒ
python analyze_experiments.py --top 10

# è¿‡æ»¤ç‰¹å®šå®éªŒ
python analyze_experiments.py --filter optimizer=ADAMW
```

### é«˜çº§åˆ†æ

```bash
# ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
python analyze_experiments.py --visualize

# å¯¼å‡ºHTMLæŠ¥å‘Š
python analyze_experiments.py --export my_report.html

# æŒ‡å®šç»“æœæ–‡ä»¶
python analyze_experiments.py --results-file /path/to/results.csv
```

### åˆ†æè¾“å‡º

```
analysis_output/
â”œâ”€â”€ training_time_distribution.png     # è®­ç»ƒæ—¶é—´åˆ†å¸ƒ
â”œâ”€â”€ hyperparameter_analysis.png       # è¶…å‚æ•°å½±å“åˆ†æ
â””â”€â”€ correlation_matrix.png           # å‚æ•°ç›¸å…³æ€§çƒ­å›¾
```

## ğŸ›ï¸ é«˜çº§åŠŸèƒ½

### 1. å¢é‡å®éªŒ

```bash
# å…ˆè¿è¡Œä¸€éƒ¨åˆ†å®éªŒ
python batch_train.py --config my_config.json --ids 1,3,5,7

# å†è¿è¡Œå‰©ä½™å®éªŒ
python batch_train.py --config my_config.json --ids 2,4,6,8
```

### 2. æ–­ç‚¹ç»­ä¼ 

```bash
# è®­ç»ƒä¸­æ–­åï¼Œæ¢å¤è®­ç»ƒ
python train_enhanced.py --resume 1 --save previous_experiment_name

# ç»§ç»­æ‰¹é‡è®­ç»ƒï¼ˆä¼šè·³è¿‡å·²å®Œæˆçš„å®éªŒï¼‰
python batch_train.py --config my_config.json
```

### 3. å®éªŒæ¯”è¾ƒ

```bash
# æ¯”è¾ƒä¸¤ä¸ªå®éªŒçš„æ€§èƒ½
python analyze_experiments.py --filter "config_optimizer=ADAMW" > adamw_results.txt
python analyze_experiments.py --filter "config_optimizer=ADAM" > adam_results.txt
```

## ğŸ“Š WandBé›†æˆ

### æ‰¹é‡å®éªŒçš„WandBç®¡ç†

```bash
# 1. ç™»å½•WandB
wandb login

# 2. æ‰¹é‡è®­ç»ƒä¼šè‡ªåŠ¨åˆ›å»ºå®éªŒ
python quick_batch.py --preset lr_comparison

# 3. åœ¨WandB dashboardä¸­æŸ¥çœ‹æ‰€æœ‰å®éªŒ
# https://wandb.ai/your_project
```

### WandBæœ€ä½³å®è·µ

1. **é¡¹ç›®å‘½å**: ä½¿ç”¨æœ‰æ„ä¹‰çš„é¡¹ç›®åï¼Œå¦‚ `SymUNet-SR-Batch-2024`
2. **å®éªŒå‘½å**: ä½¿ç”¨æ¸…æ™°çš„å®éªŒåï¼ŒåŒ…å«å…³é”®è¶…å‚æ•°
3. **æ ‡ç­¾ç®¡ç†**: åœ¨WandBç•Œé¢ä¸­ä¸ºå®éªŒæ·»åŠ æ ‡ç­¾
4. **å›¾è¡¨å¯¹æ¯”**: åˆ©ç”¨WandBçš„å¯¹æ¯”åŠŸèƒ½åˆ†æä¸åŒå®éªŒ

## âš ï¸ æ³¨æ„äº‹é¡¹

### å†…å­˜ç®¡ç†

```bash
# å†…å­˜ä¸è¶³æ—¶ï¼Œå‡å°‘æ‰¹æ¬¡å¤§å°å’Œæ¨¡å‹å®½åº¦
--batch_size 2
--symunet_pretrain_width 32
```

### æ—¶é—´ä¼°ç®—

| å®éªŒæ•°é‡ | æ¯ä¸ªå®éªŒæ—¶é—´ | æ€»æ—¶é—´ä¼°ç®— |
|----------|-------------|------------|
| 3ä¸ª      | 4å°æ—¶       | 12å°æ—¶     |
| 5ä¸ª      | 4å°æ—¶       | 20å°æ—¶     |
| 10ä¸ª     | 4å°æ—¶       | 40å°æ—¶     |
| 20ä¸ª     | 4å°æ—¶       | 80å°æ—¶     |

### ç£ç›˜ç©ºé—´

- æ¯ä¸ªå®éªŒ: ~2GB (æ¨¡å‹æƒé‡ + æ—¥å¿—)
- 20ä¸ªå®éªŒ: ~40GB
- å»ºè®®å®šæœŸæ¸…ç†: `rm -rf ../experiment/old_experiments`

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯

1. **ImportError**: ç¼ºå°‘ä¾èµ–
   ```bash
   pip install pandas seaborn matplotlib
   ```

2. **CUDA OOM**: æ˜¾å­˜ä¸è¶³
   ```bash
   # å‡å°‘batch_sizeæˆ–model_width
   --batch_size 2
   --symunet_pretrain_width 32
   ```

3. **WandBç™»å½•å¤±è´¥**
   ```bash
   wandb login --relogin
   ```

4. **æ•°æ®é›†è·¯å¾„é”™è¯¯**
   ```bash
   # æ£€æŸ¥æ•°æ®è·¯å¾„
   ls /your/data/path
   ```

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†è¾“å‡º
export DEBUG=1
python batch_train.py --config my_config.json

# æ£€æŸ¥é…ç½®æ–‡ä»¶
python -m json.tool experiments_config.json
```

## ğŸ“ å®é™…ä½¿ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šå­¦ä¹ ç‡è°ƒä¼˜

```bash
# 1. åˆ›å»ºå­¦ä¹ ç‡è°ƒä¼˜å®éªŒ
python quick_batch.py --preset lr_comparison

# 2. åˆ†æç»“æœ
python analyze_experiments.py --top 3

# 3. åŸºäºæœ€ä½³å­¦ä¹ ç‡ç»§ç»­è°ƒä¼˜
python batch_train.py --create-config
# ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨æœ€ä½³å­¦ä¹ ç‡ï¼Œæµ‹è¯•å…¶ä»–å‚æ•°
```

### æ¡ˆä¾‹2ï¼šå…¨é¢è¶…å‚æ•°æœç´¢

```bash
# 1. ç¬¬ä¸€é˜¶æ®µï¼šç²—æœç´¢
python batch_train.py --config broad_search.json

# 2. åˆ†æç»“æœï¼Œæ‰¾å‡ºæœ€ä½³åŒºåŸŸ
python analyze_experiments.py --visualize

# 3. ç¬¬äºŒé˜¶æ®µï¼šç²¾ç»†æœç´¢
python batch_train.py --config fine_search.json
```

### æ¡ˆä¾‹3ï¼šæŒç»­æ”¹è¿›

```bash
# 1. è¿è¡ŒåŸºç¡€å®éªŒ
python quick_batch.py --preset optimizer_comparison

# 2. åˆ†æå¹¶é€‰æ‹©æœ€ä½³é…ç½®
python analyze_experiments.py --export baseline_report.html

# 3. åŸºäºæœ€ä½³é…ç½®å¾®è°ƒ
python train_enhanced.py --model SYMUNET_PRETRAIN \
    --optimizer ADAMW --scheduler cosine --lr 2e-4 \
    --save final_optimized_model
```

## ğŸ¯ æœ€ä½³å®è·µ

1. **ä»ç®€å•å¼€å§‹**: å…ˆç”¨å¿«é€Ÿé¢„è®¾æ¢ç´¢å…³é”®å‚æ•°
2. **é€æ­¥æ·±å…¥**: åŸºäºç»“æœè¿›è¡Œç²¾ç»†è°ƒä¼˜
3. **è®°å½•åˆ†æ**: æ¯æ¬¡å®éªŒåéƒ½è¿›è¡Œç»“æœåˆ†æ
4. **ç‰ˆæœ¬æ§åˆ¶**: ä¿å­˜é…ç½®æ–‡ä»¶ï¼Œæ–¹ä¾¿é‡ç°å®éªŒ
5. **èµ„æºç®¡ç†**: åˆç†æ§åˆ¶å®éªŒæ•°é‡ï¼Œé¿å…èµ„æºæµªè´¹

## ğŸ“ è·å–å¸®åŠ©

- æŸ¥çœ‹å¸®åŠ©: `python script_name.py --help`
- åˆ›å»ºé…ç½®: `python batch_train.py --create-config`
- åˆ—å‡ºé¢„è®¾: `python quick_batch.py --list`
- è¯•è¿è¡Œ: æ·»åŠ  `--dry-run` å‚æ•°

---

**ç¥å®éªŒé¡ºåˆ©ï¼** ğŸš€